import streamlit as st
import tensorflow as tf
from PIL import Image
import numpy as np

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…
# ==========================================
st.set_page_config(page_title="Skin Safety System Pro", layout="centered")

st.markdown("""
    <style>
    .main { background-color: #f0f2f6; }
    .report-card { padding: 25px; border-radius: 15px; background-color: white; border-left: 6px solid #1E88E5; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); margin-top: 20px; }
    .title-text { text-align: center; color: #0D47A1; }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…
# ==========================================
st.markdown("<h1 class='title-text'>ğŸ›¡ï¸ Ù…Ù†ØµØ© Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø°ÙƒÙŠ</h1>", unsafe_allow_html=True)
st.divider()

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ---
@st.cache_resource
def load_tflite_model():
    interpreter = tf.lite.Interpreter(model_path="skin_expert_refined.tflite")
    interpreter.allocate_tensors()
    return interpreter

try:
    interpreter = load_tflite_model()
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    target_dtype = input_details[0]['dtype'] # ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    
    uploaded_file = st.file_uploader("ğŸ“¥ Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„Ø¢ÙØ©", type=["jpg", "png", "jpeg"])

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©", use_container_width=True)
        
        if st.button("ğŸ”¬ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„"):
            with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...'):
                # 1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
                img = image.convert('RGB').resize((224, 224))
                
                # 2. Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø¯Ù‚Ø© (FLOAT)
                img_array = np.array(img).astype(np.float32) / 255.0
                img_array = img_array.astype(target_dtype)
                img_array = np.expand_dims(img_array, axis=0)

                # 3. Ø§Ù„ØªÙ†Ø¨Ø¤
                interpreter.set_tensor(input_details[0]['index'], img_array)
                interpreter.invoke()
                output_data = interpreter.get_tensor(output_details[0]['index'])[0]
                
                # 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
                st.markdown("<div class='report-card'>", unsafe_allow_html=True)
                st.subheader("ğŸ“‹ Ø§Ù„Ù†ØªÙŠØ¬Ø©:")
                
                # Ø£Ø®Ø° Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹
                max_prob_index = np.argmax(output_data)
                
                # --- [Ù…Ø¹Ø¯Ù„]: Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ---
                class_names = ["Ø³Ù„ÙŠÙ… (Normal)", "ÙˆØ±Ù… Ø­Ù…ÙŠØ¯ (Benign)", "ÙˆØ±Ù… Ø®Ø¨ÙŠØ« (Malignant)"]
                
                if max_prob_index < len(class_names):
                    st.success(f"ğŸ” Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: **{class_names[max_prob_index]}**")
                else:
                    st.error("âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„Ø­Ø§Ù„Ø©ØŒ ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
                
                st.markdown("</div>", unsafe_allow_html=True)

except Exception as e:
    st.error(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ´ØºÙŠÙ„: {e}")


